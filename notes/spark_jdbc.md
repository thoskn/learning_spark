https://medium.com/@radek.strnad/tips-for-using-jdbc-i
4. Parallel read / write
Spark is a massive parallel computation system that can run on many nodes, processing hundreds of partitions at a time. Traditional SQL databases unfortunately aren’t. Level of parallel reads / writes is being controlled by appending following option to read / write actions: .option("numPartitions", parallelismLevel). The specified number controls maximal number of concurrent JDBC connections. By default you read data to a single partition which usually doesn’t fully utilize your SQL database. On the other hand the default for writes is number of partitions of your output dataset. This can potentially hammer your system and decrease your performance. Careful selection of numPartitions is a must.
Fine tuning requires another variable to the equation - available node memory. If numPartitions is lower then number of output dataset partitions, Spark runs coalesce on those partitions. Sum of their sizes can be potentially bigger than memory of a single node, resulting in a node failure.n-apache-spark-sql-396ea7b2e3d3